{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical 5 - Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-07-15T13:35:43.740Z",
     "iopub.status.busy": "2020-07-15T13:35:43.677Z",
     "iopub.status.idle": "2020-07-15T13:35:48.320Z",
     "shell.execute_reply": "2020-07-15T13:35:48.260Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set(context='talk',style='white',palette='colorblind')\n",
    "import pickle\n",
    "import matplotlib\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 0: Load and normalize count data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This practical uses the data set from https://www.nature.com/articles/s41586-018-0654-5. This is single cell transcriptomics data from ~25,000 cells from the cortex. \n",
    "\n",
    "For each of these cells, the expression of several thousand genes was measured ```['counts']```. In the original study, the authors were interested in clustering the cells into types. \n",
    "\n",
    "We made a selection of 5000 cells and the 1000 most informative genes for run time reasons. We provide you with the original cell type labels determined by the authors for comparison ```['clusters']```.\n",
    "\n",
    "The following function will apply some preprocessing steps that are standard for transcriptomics data. We normalize the data to bring columns to comparable sizes and log-transform them as they contain huge outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-11T22:07:42.093Z",
     "iopub.status.busy": "2020-06-11T22:07:42.058Z",
     "iopub.status.idle": "2020-06-11T22:07:42.138Z",
     "shell.execute_reply": "2020-06-11T22:07:41.906Z"
    }
   },
   "outputs": [],
   "source": [
    "def lognormalize_counts(tasic_dict):\n",
    "\n",
    "    # normalize and logtransform counts\n",
    "    counts = tasic_dict['counts']\n",
    "    libsizes = counts.sum(axis=1)\n",
    "    CPM = counts / libsizes * 1e+6\n",
    "    logCPM = np.log2(CPM + 1)\n",
    "    tasic_dict['logCPM'] = np.array(logCPM)\n",
    "\n",
    "    return tasic_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-11T22:07:59.318Z",
     "iopub.status.busy": "2020-06-11T22:07:59.274Z",
     "iopub.status.idle": "2020-06-11T22:07:59.447Z",
     "shell.execute_reply": "2020-06-11T22:07:59.475Z"
    }
   },
   "outputs": [],
   "source": [
    "tasic_1k = lognormalize_counts(pickle.load(open('data/tasic_subset_1kselected.pickle', 'rb')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at ```['counts']```, ```['logPCM']``` and ```['clusters']``` to get a better understanding of the data. Plot a histogram of the cell type labels provided by  ```['clusters']```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Linear dimensionality reduction with PCA\n",
    "\n",
    "In this task, you will use Principal Component Analysis (PCA) to reduce the dimensionality of the dataset.\n",
    "\n",
    "First, implement PCA \"by hand\". You can use eigenvalue/singular value decomposition from numpy/scipy but no `sklearn`-functions. Write a function that computes all possible principal components and returns them along with the fraction of variance they explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_manual(data):\n",
    "    '''\n",
    "    Function that performs PCA on the input data\n",
    "\n",
    "    input: (cells, genes)-shaped array of log transformed cell counts\n",
    "    output:\n",
    "        fraction_variance_explained: (genes,)-shaped array with the fraction of variance explained by the individual PCs\n",
    "        principal_components: (genes, genes)-shaped array containing the principal components as columns\n",
    "    '''\n",
    "    ### NOTE: Make sure the function returns the PCs sorted by the fraction of variance explained! ###\n",
    "    ###       (First column of principal_components should hold the PC with the highest variance   ###\n",
    "    ###       explained -- fraction_variance_explained should also be sorted accordingly)          ###\n",
    "    ###       Also remember to center your columns by substracting the mean of each column before  ###\n",
    "    ###       you calculate the covariance matrix to get the principal components.                 ###\n",
    "\n",
    "    # ---------------- INSERT CODE ----------------------\n",
    "\n",
    "    \n",
    "\n",
    "    # ---------------- END CODE -------------------------\n",
    "\n",
    "    return fraction_variance_explained, principal_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_expl, PCs = PCA_manual(tasic_1k['logCPM'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we explore the structure of the low-dimensional representation, we first want to know how much variance the first PCs explain: \n",
    "\n",
    "- Plot the fraction of variance explained by the `n`-th PC vs. `n`\n",
    "\n",
    "- Plot the cumulative fraction of variance explained by the first `n` PCs with largest eigenvalue vs. `n`\n",
    "\n",
    "From the latter plot you should be able to see how many PCs you need to keep to explain at least `x`% of the variance.\n",
    "\n",
    "How many components do you need to keep to explain 50%, 75%, 90% and 99%, respectively? Indicate this in your plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_PCs = len(var_expl)\n",
    "PC_ids = np.arange(1, n_PCs+1)\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "plt.subplot(121)\n",
    "\n",
    "# Plot the variance explained of the n-th PC vs. n\n",
    "# ---------------- INSERT CODE ----------------------\n",
    "\n",
    "\n",
    "\n",
    "# ---------------- END CODE -------------------------\n",
    "\n",
    "plt.subplot(122)\n",
    "\n",
    "# Plot the cumulative variance explained for the n PCs with highest variance explained vs. n\n",
    "# Indicate how many components you need to keep to explain 50%, 75%, 90% and 99% in the plot.\n",
    "\n",
    "# ---------------- INSERT CODE ----------------------\n",
    "\n",
    "\n",
    "\n",
    "# ---------------- END CODE -------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function to select the `n` PCs needed to explain at least `x`% of the variance and use this function to extract as many PCs as are needed to explain 75% of the variance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_PCs(\n",
    "    variance_explained, principal_components, percent_variance=None):\n",
    "    '''Function that selects the first n principal components necessary to explain x% of the variance\n",
    "    input:\n",
    "        variance_explained: amount of variance explained by the individual PCs\n",
    "        principal_components: contains the principal components as columns\n",
    "        percent_variance: fraction of the variance, the all PCs that are kept explain\n",
    "    output:\n",
    "        variance_explained_kept: individual amount of variance explained for the remaining PCs\n",
    "        principal_components_kept: remaining principal components, shape (genes,n_PCs_kept)\n",
    "    '''\n",
    "\n",
    "    # ---------------- INSERT CODE ----------------------\n",
    "\n",
    "    \n",
    "    \n",
    "    # ---------------- END CODE -------------------------\n",
    "\n",
    "    return variance_explained_kept, principal_components_kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, PCs75 = select_PCs(var_expl, PCs, percent_variance=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the representation of the data in this lower dimensional representation, write a function that compute the PC scores for each cell, i.e. that projects the original data matrix on the low-dimensional subspace provided by the first `n` PCs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_PCA_scores(data, principal_components):\n",
    "    '''Function that returns the PC scores for each data point\n",
    "    input:\n",
    "        data                 --- (cells, genes)-shaped array of log transformed cell counts\n",
    "        principal_components --- contains the principal components as columns\n",
    "    output:\n",
    "        pc_scores            --- (cells, n_PCs_kept)-shaped array of PC scores\n",
    "    '''\n",
    "\n",
    "    # ---------------- INSERT CODE ----------------------\n",
    "\n",
    "    \n",
    "    \n",
    "    # ---------------- END CODE -------------------------\n",
    "\n",
    "    return pc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasic_1k['PCA_75'] = compute_PCA_scores(tasic_1k['logCPM'], PCs75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the top 5 PCs as a pairwise scatterplot. Use one subplot for each pair of components.\n",
    "\n",
    "Use the colors provided in `tasic_1k['clusterColors']` and the cluster information in `tasic_1k['clusters']` to color each data point according to its original cluster identity.\n",
    "\n",
    "The colors indicate the family of the cell type:\n",
    "\n",
    "- greenish colors: excitatory neurons\n",
    "- orange colors: somatostatin positive interneurons\n",
    "- pinkish colors: VIP-postive interneurons\n",
    "- reddish colors: parvalbumin positive interneurons\n",
    "- dark colors: non-neurons (glia etc)\n",
    "\n",
    "What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_PCs(data_transformed, color_per_datapoint):\n",
    "    '''Function that plots the scores of the 10 pairs of the top 5 PCs against each other.\n",
    "        inputs:\n",
    "            data_transformed    -- (cells, n_PCs_kept)-shaped array of PC scores\n",
    "            color_per_datapoint -- (cells,)-shaped array of color strings, one color for each cell\n",
    "    '''\n",
    "\n",
    "    # ---------------- INSERT CODE ----------------------\n",
    "\n",
    "    \n",
    "    \n",
    "    # ---------------- END CODE -------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_per_datapoint = tasic_1k['clusterColors'][tasic_1k['clusters']]\n",
    "plot_PCs(tasic_1k['PCA_75'], color_per_datapoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Comparison with PCA implemented by sklearn\n",
    "\n",
    "Use the PCA implementation of sklearn to check whether your PCA implementation is correct and obtain some insights into numerical precision of the algorithms underlying PCA implementations. Note that the sklearn implementation of PCA switches the dimensions of the matrix, so you will have to transpose your principal components matrix to get the same output as in the manual implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_sklearn(data):\n",
    "    '''\n",
    "    Function that performs PCA on the input data, using sklearn\n",
    "\n",
    "    input: (cells, genes)-shaped array of log transformed cell counts\n",
    "    output:\n",
    "        fraction_variance_explained: (genes,)-shaped array with the fraction of variance explained by the individual PCs\n",
    "        principal_components: (genes, genes)-shaped array containing the principal components as columns\n",
    "    '''\n",
    "\n",
    "    # ---------------- INSERT CODE ----------------------\n",
    "\n",
    "    \n",
    "    \n",
    "    # ---------------- END CODE -------------------------\n",
    "\n",
    "    return fraction_variance_explained, principal_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-06-11T22:18:44.632Z",
     "iopub.status.busy": "2020-06-11T22:18:44.610Z",
     "iopub.status.idle": "2020-06-11T22:18:44.967Z",
     "shell.execute_reply": "2020-06-11T22:18:45.297Z"
    }
   },
   "outputs": [],
   "source": [
    "# do sklearn-PCA on selected genes\n",
    "var_expl_sklearn, PCs_sklearn = PCA_sklearn(tasic_1k['logCPM'])\n",
    "# select components as before\n",
    "_, PCs_sklearn75 = select_PCs(var_expl_sklearn, PCs_sklearn, 0.75)\n",
    "# get PC scores\n",
    "PCA_75_sklearn = compute_PCA_scores(tasic_1k['logCPM'], PCs_sklearn75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see if your manual PCA yielded the same PC weights as the sklearn PCA, we can just take the two matrices of principal components and plot their entries against each other. (Note: This again assumes they are sorted by variance explained and the order of dimensions in your weight matrix compared to the sklearn weight matrix is the same (change if necessary).)\n",
    "\n",
    "Use the following plot to compare the results to your own implementation (here plotting the weights of the first 100 PCs against each other). What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_evs_to_compare = 100\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(PCs_sklearn[:, :n_evs_to_compare].flatten(),\n",
    "            PCs[:, :n_evs_to_compare].flatten(), s=5, alpha=0.1)\n",
    "plt.plot([-.7, .7], [-.7, .7], ':', c='tab:gray', label='same sign', alpha=0.3)\n",
    "plt.plot([-.7, .7], [.7, -.7], '--', c='tab:gray', label='sign flipped', alpha=0.3)\n",
    "plt.legend()\n",
    "plt.xlabel('sklearn PCA weight')\n",
    "plt.ylabel('manual PCA weight')\n",
    "plt.title('Weights of the first %u manual PCs against the sklearn ones' % (n_evs_to_compare))\n",
    "\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional reading about the sign of PCs: https://stats.stackexchange.com/questions/88880/does-the-sign-of-scores-or-of-loadings-in-pca-or-fa-have-a-meaning-may-i-revers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Nonlinear dimensionality reduction with t-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you will use the nonlinear dimensionality reduction technique tSNE and look at visualizations of the data set. Plot the result of default t-SNE with the original cluster colors. For this and the following tasks, use the PCs explaining 75% of the variance ```PCA_75_sklearn``` you computed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def plot_tsne(tsne_results, clusters=tasic_1k['clusters'], labels=['']):\n",
    "    '''Plotting function for tsne results, creates one or multiple plots of tSNE-transformed data.\n",
    "       If the clustering is the original one (default), original cluster colors will be used. Otherwise,\n",
    "       colors will be a random permutation.\n",
    "\n",
    "    input:\n",
    "        tsne_results: (n, 2)-shaped array containing tSNE-transformed data or list of such arrays\n",
    "                      (output of the fit_transform function of sklearn tSNE)\n",
    "        clusters: (n,)-shaped array containing cluster labels or list of such arrays\n",
    "        labels: optional, list of titles for the subplots\n",
    "    '''\n",
    "\n",
    "    if type(tsne_results) == list:  # make sure we can do both single and multiple plots and are flexible regarding input\n",
    "        num_plots = len(tsne_results)\n",
    "    else:\n",
    "        num_plots = 1\n",
    "        tsne_results = [tsne_results]\n",
    "    if type(clusters) == list:\n",
    "        num_clusters = len(clusters)\n",
    "        num_plots = num_plots * num_clusters\n",
    "        tsne_results = tsne_results * num_clusters\n",
    "    else:\n",
    "        clusters = [clusters] * num_plots\n",
    "\n",
    "    if len(labels) == 1:\n",
    "        labels = labels * num_plots\n",
    "\n",
    "    n_clusters = len(np.unique(clusters))      # ensure a long enough color list even if we plot more than\n",
    "    n_colors = len(tasic_1k['clusterColors'])  # the original number of clusters\n",
    "    if n_clusters > n_colors:\n",
    "        n_extra_colors = n_clusters - n_colors\n",
    "        colors = np.concatenate((tasic_1k['clusterColors'], tasic_1k['clusterColors'][:n_extra_colors]))\n",
    "    else:\n",
    "        colors = tasic_1k['clusterColors']\n",
    "\n",
    "    fig, ax = plt.subplots(num_plots, 1, figsize=(10, num_plots*10))\n",
    "    if num_plots == 1:\n",
    "        if not np.all(tasic_1k['clusters'] == clusters[0]):\n",
    "            current_colors = np.random.permutation(colors)\n",
    "        else:\n",
    "            current_colors = colors\n",
    "        ax.scatter(tsne_results[0][:, 0], tsne_results[0][:, 1], s=1, color=current_colors[clusters[0]])\n",
    "        ax.set_title(labels[0])\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_axis_off()\n",
    "    else:\n",
    "        for i in range(num_plots):\n",
    "            if not np.all(tasic_1k['clusters'] == clusters[i]):\n",
    "                current_colors = np.random.permutation(colors)\n",
    "            else:\n",
    "                current_colors = colors\n",
    "            ax[i].scatter(tsne_results[i][:, 0], tsne_results[i][:, 1], s=1, color=current_colors[clusters[i]])\n",
    "            ax[i].set_title(labels[i])\n",
    "            ax[i].set_xticks([])\n",
    "            ax[i].set_yticks([])\n",
    "            ax[i].set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cells to set the random seed/random state, run tSNE and plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# fit TSNE\n",
    "tsne_default = TSNE(random_state=1)\n",
    "tsne_results = tsne_default.fit_transform(PCA_75_sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "\n",
    "original_clusters = tasic_1k['clusters']\n",
    "plot_tsne(tsne_results, original_clusters, labels=['default t-SNE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t-SNE has one main parameter called perplexity, which trades of local and global structure. Its default value is 30. Run the tSNE with some other perplexity values (e.g. 5, 100), plot the results next to each other and explain what you observe. In particular, compare with the PCA plot above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try different perplexities\n",
    "\n",
    "# ---------------- INSERT CODE ----------------------\n",
    "\n",
    "\n",
    "\n",
    "# ---------------- END CODE -------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results\n",
    "\n",
    "# ---------------- INSERT CODE ----------------------\n",
    "\n",
    "\n",
    "\n",
    "# ---------------- END CODE -------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "nteract": {
   "version": "0.24.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
